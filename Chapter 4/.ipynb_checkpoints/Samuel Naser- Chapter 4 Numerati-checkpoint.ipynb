{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classification Based on Item Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<ul>\n",
    "    <li>Collaborative filtering has \"rich get richer\" effect, neglecting to recognize newer bands </li> \n",
    "    <li>Music Genome Project broke songs down into quantitive attributes </li>\n",
    "    <li>For example: might have \"Genre\" attribute with 1 = Rock, 2 = Pop, etc..\n",
    "</ul> \n",
    "\n",
    "Flaw with our usual methods: <b>DISTANCE MEANS NOTHING WITH CATEGORICAL DATA!</b> \n",
    "Instead, we have to <b>split the categories out</b> and put them on numerical scale (e.g. 2/5 Rock, 4/5 Rap) \n",
    "\n",
    "Once we have done this, we can find <b>distance</b> between any two songs with normal distance methods (Manhattan, Cosine sim., etc.)- this is effectively \"rating\" the items themselves across a series of attributes\n",
    "\n",
    "We also gain the ability to <b>EXPLAIN</b> our recommendations! The attributes (vocal style, keyboard intensity, etc.) which are closest can be said to \"explain\" the recommendation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem of Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Certain variables exist on different <b>scales</b>- for example: $100,000 net worth vs 3 cars owned. The net worth would dominate our distance calculations \n",
    "\n",
    "How can we fix this tremendous problem?? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Normalization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One common method of normalization is <b>bringing data between 0 and 1</b>. Formula looks like this: \n",
    "\n",
    "$$ \\frac{x - Min_x}{Max_x - Min_x} $$ \n",
    "\n",
    "This method, however, is <b>NAIVE!</b> Ok, maybe it's appropriate sometimes, but <b>STANDARD SCORE (Z-SCORE)</b> IS BETTER! and the formula is <b>SHOWN BELOW</b> (denominator is std. deviation)\n",
    "\n",
    "$$ Z_s = \\frac{x - \\bar{x}}{\\sqrt{\\frac{\\sum{x_i - \\bar{x}^2}}{card(x)}}} $$ \n",
    "\n",
    "Outliers often throw off standard deviation, so we use <b>modified standard score</b> \n",
    "\n",
    "$$asd = \\frac{1}{card(x)}\\sum_i{|x_i - median|} $$ \n",
    "\n",
    "Modified standard score is <b>(EACH VALUE - MEDIAN) / (Absolute Standard Deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### When to normalize? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Should normalize when: \n",
    "<ul>\n",
    "    <li>Method calculates distance based on values of their features </li> \n",
    "    <li>Scale of the different features is different </li> \n",
    "</ul> \n",
    "\n",
    "TRADEOFFS: Normalization isn't always necessary, and in fact sometimes <i>reduces</i> accuracy. There is also a <b>computational cost</b> involved with normalization to consider. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Back to Pandora! :D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\"Likes\" and \"Dislikes\" can oftentimes group themselves along parameters. For example: if we plot \"driving beat\" against \"dirty guitar\" (1-5 scale), we may find the Likes and Dislikes cluster together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Simplest method is to <b>assume mystery class (like vs dislike) will be same as nearest neighbor!</b> This is arguably the most rudimentary form of classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### A classifier is a program that uses an object's attributes to figure out which class it belongs to! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Possible applications (note: classification we have done so far is item-based): \n",
    "<ul> \n",
    "    <li>Twitter sentiment classification </li> \n",
    "    <li>Automatic identification of people in photographs</li> \n",
    "    <li>Targeted political ads (classifying people into demographics)</li> \n",
    "    <li>Targeted marketing (likely buyers)</li> \n",
    "    <li>Health and the Quantified Self</li> \n",
    "    <li>Terrorist vs Non-Terrorist (these algorithms could use some work since I get pulled aside every flight I take)</li> \n",
    "\n",
    "Modified standard scores are commonly applied devices in classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCENT ACCURACY: 80.0  WITH METHOD range\n",
      "PERCENT ACCURACY: 80.0  WITH METHOD asd\n"
     ]
    }
   ],
   "source": [
    "#my implementation of nearest neighbor classifier\n",
    "class Classifier(object): \n",
    "    \n",
    "    def __init__(self, inputFile, nMethod):\n",
    "        self.nMethod = nMethod\n",
    "        self.medianDeviation = []\n",
    "        self.minMax = []\n",
    "        f = open(inputFile)\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "        self.format = lines[0].strip().split('\\t')\n",
    "        self.data = []\n",
    "        for line in lines[1:]:\n",
    "            fields = line.strip().split('\\t')\n",
    "            ignore = []\n",
    "            vector = []\n",
    "            for i in range(len(fields)):\n",
    "                if self.format[i] == 'num':\n",
    "                    vector.append(int(fields[i]))\n",
    "                elif self.format[i] == 'comment':\n",
    "                    ignore.append(fields[i])\n",
    "                elif self.format[i] == 'class':\n",
    "                    classification = fields[i]\n",
    "            self.data.append((classification, vector, ignore)) \n",
    "        \n",
    "        self.vectorLength = len(self.data[0][1])\n",
    "        for v in range(self.vectorLength): \n",
    "            self.normalizeColumn(v)\n",
    "        \n",
    "    def median(self, attribs):\n",
    "        if attribs == []:\n",
    "            return None \n",
    "        \n",
    "        attribs = sorted(attribs)\n",
    "        if len(attribs) % 2 == 1: \n",
    "            return attribs[(len(attribs)+1)/2 - 1]\n",
    "        else: \n",
    "            return float(sum(attribs[(len(attribs)/2)-1: len(attribs)/2 +1]))/2\n",
    "        \n",
    "    def absStandardDeviation(self, attribs, median): \n",
    "        total = 0.0 \n",
    "        for x in attribs: \n",
    "            total += abs(x - median)\n",
    "        \n",
    "        return total / len(attribs)\n",
    "\n",
    "    def normalizeColumn(self, columnIndex):\n",
    "        columnValues = [] \n",
    "        columnValues = [v[1][columnIndex] for v in self.data]\n",
    "    \n",
    "        median = self.median(columnValues)\n",
    "        asd = self.absStandardDeviation(columnValues, median)\n",
    "        mx = max(columnValues)\n",
    "        mn = min(columnValues)\n",
    "        #we store this so we can convert any NEW data to its standard-score equivalent\n",
    "        self.medianDeviation.append((median, asd))\n",
    "        self.minMax.append((mn,mx))\n",
    "        for v in self.data: \n",
    "            if self.nMethod == 'asd':\n",
    "                v[1][columnIndex] = self.normalize(v[1][columnIndex], median, asd)\n",
    "            elif self.nMethod == 'range': \n",
    "                v[1][columnIndex] = self.boring(v[1][columnIndex], mn, mx)\n",
    "                        \n",
    "    def normalize(self, value, median, asd): \n",
    "        return (value - median) / asd \n",
    "\n",
    "    def boring(self, v, mn, mx): \n",
    "        return float((v - mn))/(mx - mn)\n",
    "    \n",
    "    def normalizeInputVector(self, vec): \n",
    "        vector = list(vec)\n",
    "        for i in xrange(len(vec)): \n",
    "            (med, asd) = self.medianDeviation[i]\n",
    "            vector[i] = (vector[i] - med) / asd\n",
    "        return vector\n",
    "\n",
    "    def boringNormalizeVector(self, vec): \n",
    "        vector = list(vec)\n",
    "        for i in xrange(len(vec)): \n",
    "            vector[i] = float((vector[i] - self.minMax[i][0])) / (self.minMax[i][1] - self.minMax[i][0])\n",
    "        return vector \n",
    "\n",
    "    \n",
    "    def manhattan(self, vec1, vec2): \n",
    "        sum = 0.0 \n",
    "        for i in xrange(len(vec1)): \n",
    "            sum += abs(vec1[i] - vec2[i])\n",
    "        return sum \n",
    "    \n",
    "    def nearestNeighbor(self, vec1): \n",
    "        distances = []\n",
    "        for items in self.data: \n",
    "            distances.append((self.manhattan(vec1, items[1]), items[0]))\n",
    "        return sorted(distances)[0]\n",
    "    \n",
    "    def classify(self, vec):\n",
    "        return self.nearestNeighbor(vec)\n",
    "        \n",
    "    def testDataFromFile(self, testPath):\n",
    "        correct = 0.0\n",
    "        incorrect = 0.0 \n",
    "        \n",
    "        f = open(testPath, 'r') \n",
    "        lines = [x.strip() for x in f.readlines()] \n",
    "        f.close() \n",
    "\n",
    "        for athlete in lines: \n",
    "            s = athlete.split('\\t') \n",
    "            currentClass = s[1]\n",
    "            cVec = [int(s[2]),int(s[3])]\n",
    "            if self.nMethod == 'asd':\n",
    "                ncVec = self.normalizeInputVector(cVec)\n",
    "            elif self.nMethod == 'range':\n",
    "                ncVec = self.boringNormalizeVector(cVec)\n",
    "            prediction = self.classify(ncVec)\n",
    "            if prediction[1] == currentClass: \n",
    "                correct += 1 \n",
    "            else: \n",
    "                incorrect += 1 \n",
    "\n",
    "        print \"PERCENT ACCURACY:\", (correct / (correct + incorrect))*100, \" WITH METHOD\", self.nMethod\n",
    "            \n",
    "c = Classifier(\"athletesTrainingSet.txt\", \"range\") \n",
    "c.testDataFromFile(\"athletesTestSet.txt\")\n",
    "\n",
    "d = Classifier(\"athletesTrainingSet.txt\", \"asd\") \n",
    "d.testDataFromFile(\"athletesTestSet.txt\")\n",
    "\n",
    "#I cannot believe how long this code took to write. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>assert</b> keyword useful in Python to test code and ensure certain conditions are met at runtime. \n",
    "\n",
    "    “it is important that each part of the specification be turned into a piece of code that\n",
    "    implements it and a test that tests it. If you don’t have tests like these then you don’t know\n",
    "    when you are done, you don’t know if you got it right, and you don’t know that any future\n",
    "    changes might be breaking something.” - Peter Norvig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Normalization:</b> transforming data from its original scale to 0-1\n",
    "\n",
    "<b>Standardization:</b> transforming data so that 0 = average, and either side are proportions of std dev from average"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
