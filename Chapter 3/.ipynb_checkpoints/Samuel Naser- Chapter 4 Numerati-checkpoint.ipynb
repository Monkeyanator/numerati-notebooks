{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Based on Item Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Collaborative filtering has \"rich get richer\" effect, neglecting to recognize newer bands </li> \n",
    "    <li>Music Genome Project broke songs down into quantitive attributes </li>\n",
    "    <li>For example: might have \"Genre\" attribute with 1 = Rock, 2 = Pop, etc..\n",
    "</ul> \n",
    "\n",
    "Flaw with our usual methods: <b>DISTANCE MEANS NOTHING WITH CATEGORICAL DATA!</b> \n",
    "Instead, we have to <b>split the categories out</b> and put them on numerical scale (e.g. 2/5 Rock, 4/5 Rap) \n",
    "\n",
    "Once we have done this, we can find <b>distance</b> between any two songs with normal distance methods (Manhattan, Cosine sim., etc.)- this is effectively \"rating\" the items themselves across a series of attributes\n",
    "\n",
    "We also gain the ability to <b>EXPLAIN</b> our recommendations! The attributes (vocal style, keyboard intensity, etc.) which are closest can be said to \"explain\" the recommendation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem of Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain variables exist on different <b>scales</b>- for example: $100,000 net worth vs 3 cars owned. The net worth would dominate our distance calculations \n",
    "\n",
    "How can we fix this tremendous problem?? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common method of normalization is <b>bringing data between 0 and 1</b>. Formula looks like this: \n",
    "\n",
    "$$ \\frac{x - Min_x}{Max_x - Min_x} $$ \n",
    "\n",
    "This method, however, is <b>NAIVE!</b> Ok, maybe it's appropriate sometimes, but <b>STANDARD SCORE (Z-SCORE)</b> IS BETTER! and the formula is <b>SHOWN BELOW</b> (denominator is std. deviation)\n",
    "\n",
    "$$ Z_s = \\frac{x - \\bar{x}}{\\sqrt{\\frac{\\sum{x_i - \\bar{x}^2}}{card(x)}}} $$ \n",
    "\n",
    "Outliers often throw off standard deviation, so we use <b>modified standard score</b> \n",
    "\n",
    "$$asd = \\frac{1}{card(x)}\\sum_i{|x_i - median|} $$ \n",
    "\n",
    "Modified standard score is <b>(EACH VALUE - MEDIAN) / (Absolute Standard Deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to normalize? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should normalize when: \n",
    "<ul>\n",
    "    <li>Method calculates distance based on values of their features </li> \n",
    "    <li>Scale of the different features is different </li> \n",
    "</ul> \n",
    "\n",
    "TRADEOFFS: Normalization isn't always necessary, and in fact sometimes <i>reduces</i> accuracy. There is also a <b>computational cost</b> involved with normalization to consider. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Pandora! :D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Likes\" and \"Dislikes\" can oftentimes group themselves along parameters. For example: if we plot \"driving beat\" against \"dirty guitar\" (1-5 scale), we may find the Likes and Dislikes cluster together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplest method is to <b>assume mystery class (like vs dislike) will be same as nearest neighbor!</b> This is arguably the most rudimentary for of classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A classifier is a program that uses an object's attributes to figure out which class it belongs to! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible applications (note: classification we have done so far is item-based): \n",
    "<ul> \n",
    "    <li>Twitter sentiment classification </li> \n",
    "    <li>Automatic identification of people in photographs</li> \n",
    "    <li>Targeted political ads (classifying people into demographics)</li> \n",
    "    <li>Targeted marketing (likely buyers)</li> \n",
    "    <li>Health and the Quantified Self</li> \n",
    "    <li>Terrorist vs Non-Terrorist (these algorithms could use some work since I get pulled aside every flight I take)</li> \n",
    "\n",
    "Modified standard scores are commonly applied devices in classification. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
